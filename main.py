from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import time
import json
import pandas as pd
import os
import random
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
import threading

# KhÃ³a Ä‘á»ƒ Ä‘á»“ng bá»™ hÃ³a ghi vÃ o file CSV
file_lock = threading.Lock()

def setup_driver():
    """Khá»Ÿi táº¡o trÃ¬nh duyá»‡t Chrome"""
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    
    # User-Agent giá»‘ng trÃ¬nh duyá»‡t tháº­t
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    
    # Giáº£ máº¡o thÃ´ng tin webdriver
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    
    return driver

def crawl_property_info(url, position=0, total=0):
    """CÃ o thÃ´ng tin báº¥t Ä‘á»™ng sáº£n tá»« URL cá»¥ thá»ƒ"""
    driver = setup_driver()
    property_data = {}  
    
    try:
        tqdm.write(f"[{position}/{total}] Äang truy cáº­p: {url}")
        driver.get(url)
        wait_time = random.uniform(1, 1.5)
        # Äá»£i trang táº£i xong
        time.sleep(wait_time)
        
        # TÃ¬m táº¥t cáº£ cÃ¡c tháº» div cÃ³ class="re__pr-specs-content-item"
        spec_items = driver.find_elements(By.CSS_SELECTOR, "div.re__pr-specs-content-item")
        
        for item in spec_items:
            text = item.text.strip()
            if "\n" in text:
                # TÃ¡ch dÃ²ng Ä‘áº§u tiÃªn lÃ m tÃªn thuá»™c tÃ­nh, pháº§n cÃ²n láº¡i lÃ  giÃ¡ trá»‹
                parts = text.split("\n", 1)
                property_name = parts[0].strip()
                property_value = parts[1].strip()
                property_data[property_name] = property_value
        
        # TÃ¬m tháº» div cÃ³ class="re__pr-short-info-item js__pr-config-item"
        short_info_items = driver.find_elements(By.CSS_SELECTOR, "div.re__pr-short-info-item.js__pr-config-item")
        
        for item in short_info_items:
            text = item.text.strip()
            if "\n" in text:
                parts = text.split("\n", 1)
                property_name = parts[0].strip()
                property_value = parts[1].strip()
                property_data[property_name] = property_value
        
        # Chuyá»ƒn dictionary thÃ nh DataFrame
        df = pd.DataFrame([property_data])
        return df, None  # Tráº£ vá» DataFrame vÃ  khÃ´ng cÃ³ lá»—i
            
    except Exception as e:
        error_msg = str(e)
        tqdm.write(f"  âŒ Lá»—i: {error_msg}")
        # Váº«n tráº£ vá» DataFrame vá»›i URL Ä‘á»ƒ ghi láº¡i thÃ´ng tin tháº¥t báº¡i
        return pd.DataFrame([{"URL": url, "Error": error_msg}]), error_msg
    finally:
        driver.quit()

def read_urls_from_csv(csv_file='linkProduct.csv'):
    """Äá»c danh sÃ¡ch URL tá»« file CSV"""
    try:
        # Kiá»ƒm tra náº¿u file tá»“n táº¡i
        if not os.path.exists(csv_file):
            print(f"File {csv_file} khÃ´ng tá»“n táº¡i.")
            
            # Kiá»ƒm tra xem cÃ³ file JSON khÃ´ng Ä‘á»ƒ chuyá»ƒn Ä‘á»•i
            json_file = csv_file.replace('.csv', '.json')
            if os.path.exists(json_file):
                print(f"TÃ¬m tháº¥y file JSON {json_file}, Ä‘ang chuyá»ƒn Ä‘á»•i thÃ nh CSV...")
                with open(json_file, 'r', encoding='utf-8') as f:
                    urls = json.load(f)
                
                df = pd.DataFrame({'url': urls})
                df.to_csv(csv_file, index=False)
                print(f"ÄÃ£ chuyá»ƒn Ä‘á»•i thÃ nh cÃ´ng {len(urls)} URL sang file {csv_file}")
                return urls
            return []
            
        # Äá»c file CSV
        df = pd.read_csv(csv_file)
        
        # TÃ¬m cá»™t chá»©a URL (cÃ³ thá»ƒ lÃ  'url', 'link', hoáº·c cá»™t Ä‘áº§u tiÃªn)
        url_column = None
        for col in ['url', 'URL', 'link', 'Link']:
            if col in df.columns:
                url_column = col
                break
        
        if not url_column and len(df.columns) > 0:
            # Náº¿u khÃ´ng tÃ¬m tháº¥y cá»™t tÃªn cá»¥ thá»ƒ, sá»­ dá»¥ng cá»™t Ä‘áº§u tiÃªn
            url_column = df.columns[0]
        
        if url_column:
            urls = df[url_column].tolist()
            print(f"ÄÃ£ Ä‘á»c {len(urls)} URL tá»« file {csv_file}")
            return urls
        else:
            print(f"KhÃ´ng tÃ¬m tháº¥y cá»™t URL trong file {csv_file}")
            return []
            
    except Exception as e:
        print(f"Lá»—i khi Ä‘á»c file CSV: {e}")
        return []

def append_to_csv(df, output_file='property_data.csv', batch_count=1):
    """
    Ghi DataFrame vÃ o file CSV Ä‘áº£m báº£o tÆ°Æ¡ng thÃ­ch vá»›i dá»¯ liá»‡u hiá»‡n cÃ³
    
    Parameters:
        df (DataFrame): DataFrame cáº§n ghi
        output_file (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file CSV Ä‘áº§u ra
        batch_count (int): Sá»‘ batch Ä‘á»ƒ hiá»ƒn thá»‹ trong thÃ´ng bÃ¡o
    """
    # Sá»­ dá»¥ng lock Ä‘á»ƒ trÃ¡nh Ä‘á»¥ng Ä‘á»™ khi nhiá»u luá»“ng cÃ¹ng ghi file
    with file_lock:
        # Kiá»ƒm tra xem file Ä‘Ã£ tá»“n táº¡i chÆ°a
        file_exists = os.path.exists(output_file)
        
        if file_exists:
            try:
                # Äá»c header cá»§a file hiá»‡n cÃ³ Ä‘á»ƒ kiá»ƒm tra cáº¥u trÃºc
                existing_df = pd.read_csv(output_file)
                
                # So sÃ¡nh cáº¥u trÃºc cá»™t
                existing_cols = set(existing_df.columns)
                new_cols = set(df.columns)
                
                if existing_cols != new_cols:
                    tqdm.write(f"PhÃ¡t hiá»‡n cáº¥u trÃºc cá»™t khÃ¡c nhau. Äang káº¿t há»£p dá»¯ liá»‡u...")
                    # Káº¿t há»£p DataFrame má»›i vá»›i dá»¯ liá»‡u hiá»‡n cÃ³
                    combined_df = pd.concat([existing_df, df], ignore_index=True)
                    
                    # Ghi láº¡i toÃ n bá»™ file vá»›i thanh tiáº¿n trÃ¬nh
                    tqdm.write(f"Äang ghi {len(combined_df)} báº£n ghi vÃ o file...")
                    combined_df.to_csv(output_file, index=False, encoding='utf-8-sig')
                    tqdm.write(f"âœ… ÄÃ£ lÆ°u lÃ´ thá»© {batch_count}: {len(df)} báº£n ghi má»›i, tá»•ng {len(combined_df)} báº£n ghi")
                    return
                
                # Náº¿u cáº¥u trÃºc cá»™t giá»‘ng nhau, chá»‰ cáº§n append
                df.to_csv(output_file, mode='a', header=False, index=False, encoding='utf-8-sig')
                tqdm.write(f"âœ… ÄÃ£ lÆ°u lÃ´ thá»© {batch_count}: {len(df)} báº£n ghi")
                
            except Exception as e:
                tqdm.write(f"âŒ Lá»—i khi xá»­ lÃ½ file: {e}")
                # Náº¿u cÃ³ lá»—i, ghi Ä‘Ã¨ file
                df.to_csv(output_file, index=False, encoding='utf-8-sig')
                tqdm.write(f"ÄÃ£ ghi Ä‘Ã¨ file vá»›i lÃ´ dá»¯ liá»‡u thá»© {batch_count}")
        else:
            # Náº¿u file chÆ°a tá»“n táº¡i, táº¡o má»›i
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
            tqdm.write(f"âœ… ÄÃ£ táº¡o file má»›i vÃ  lÆ°u {len(df)} báº£n ghi vÃ o {output_file}")

# HÃ m má»›i Ä‘á»ƒ xá»­ lÃ½ má»™t lÃ´ URLs
def process_batch(urls_batch, output_file, batch_idx, total_batches):
    results = []
    batch_size = len(urls_batch)
    
    # CÃ o dá»¯ liá»‡u cho táº¥t cáº£ URL trong lÃ´
    for idx, url in enumerate(urls_batch):
        df_result, error = crawl_property_info(url, idx+1, batch_size)
        if not df_result.empty:
            results.append(df_result)
    
    # Náº¿u cÃ³ káº¿t quáº£, káº¿t há»£p vÃ  lÆ°u
    if results:
        combined_df = pd.concat(results, ignore_index=True)
        append_to_csv(combined_df, output_file, batch_idx)

# HÃ m má»›i Ä‘á»ƒ xá»­ lÃ½ Ä‘a luá»“ng
def process_with_multithreading(urls, num_threads=4, batch_size=10, output_file='property_data.csv'):
    """Xá»­ lÃ½ danh sÃ¡ch URL vá»›i Ä‘a luá»“ng"""
    total_urls = len(urls)
    
    # Chia danh sÃ¡ch URL thÃ nh cÃ¡c lÃ´
    batches = [urls[i:i + batch_size] for i in range(0, total_urls, batch_size)]
    num_batches = len(batches)
    
    print(f"\nğŸ§µ Sá»­ dá»¥ng {num_threads} luá»“ng Ä‘á»ƒ xá»­ lÃ½ {total_urls} URL trong {num_batches} lÃ´")
    
    # Sá»­ dá»¥ng ThreadPoolExecutor Ä‘á»ƒ cháº¡y Ä‘a luá»“ng
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        # Submit cÃ¡c tÃ¡c vá»¥ vÃ  láº¥y cÃ¡c Future objects
        futures = []
        for i, batch in enumerate(batches):
            future = executor.submit(process_batch, batch, output_file, i+1, num_batches)
            futures.append(future)
        
        # Theo dÃµi tiáº¿n trÃ¬nh vá»›i tqdm
        with tqdm(total=num_batches, desc="Tiáº¿n trÃ¬nh xá»­ lÃ½ cÃ¡c lÃ´") as pbar:
            # Äáº¿m sá»‘ lÃ´ Ä‘Ã£ hoÃ n thÃ nh
            completed = 0
            # Kiá»ƒm tra tiáº¿n trÃ¬nh cá»§a cÃ¡c future
            while completed < num_batches:
                new_completed = sum(1 for f in futures if f.done())
                if new_completed > completed:
                    pbar.update(new_completed - completed)
                    completed = new_completed
                time.sleep(0.1)

if __name__ == "__main__":
    # File Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra
    input_csv = 'linkProduct.csv'
    output_csv = 'property_data.csv'
    batch_size = 10
    num_threads = 4  # Sá»‘ luá»“ng xá»­ lÃ½ Ä‘á»“ng thá»i
    
    # Hiá»ƒn thá»‹ tiÃªu Ä‘á»
    print("\n" + "="*70)
    print("ğŸ  Báº®T Äáº¦U CÃ€O Dá»® LIá»†U Báº¤T Äá»˜NG Sáº¢N ÄA LUá»’NG")
    print("="*70 + "\n")
    
    # Äá»c cÃ¡c URL tá»« file CSV
    print("ğŸ“‚ Äang Ä‘á»c danh sÃ¡ch URL...")
    urls = read_urls_from_csv(input_csv)
    
    if urls:
        print(f"ğŸ” ÄÃ£ tÃ¬m tháº¥y {len(urls)} URL Ä‘á»ƒ xá»­ lÃ½, batch size: {batch_size}, threads: {num_threads}\n")
        
        # Hiá»ƒn thá»‹ thá»i gian báº¯t Ä‘áº§u
        start_time = time.time()
        
        # Xá»­ lÃ½ URL vá»›i Ä‘a luá»“ng
        process_with_multithreading(urls, num_threads, batch_size, output_csv)
        
        # TÃ­nh thá»i gian thá»±c hiá»‡n
        elapsed_time = time.time() - start_time
        hours, remainder = divmod(elapsed_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        
        # Hiá»ƒn thá»‹ thÃ´ng bÃ¡o hoÃ n thÃ nh
        print("\n" + "="*70)
        print(f"âœ… HOÃ€N THÃ€NH! Thá»i gian: {int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}")
        print(f"ğŸ“Š Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: {output_csv}")
        print("="*70)
    else:
        print("âŒ KhÃ´ng cÃ³ URL Ä‘á»ƒ xá»­ lÃ½.")